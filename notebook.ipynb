{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comment analysis using GRU\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:52.264531Z",
     "start_time": "2024-03-14T07:56:50.931012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.2.1)\r\n",
      "Requirement already satisfied: nltk~=3.8.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.8.1)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.2.2)\r\n",
      "Requirement already satisfied: contractions in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.1.73)\r\n",
      "Requirement already satisfied: tensorflow in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.16.1)\r\n",
      "Requirement already satisfied: joblib~=1.2.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\r\n",
      "Requirement already satisfied: click in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from nltk~=3.8.1->-r requirements.txt (line 3)) (8.1.7)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from nltk~=3.8.1->-r requirements.txt (line 3)) (2023.10.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from nltk~=3.8.1->-r requirements.txt (line 3)) (4.65.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.11.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 4)) (2.2.0)\r\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from contractions->-r requirements.txt (line 5)) (0.0.24)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (24.3.7)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (23.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (4.25.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (2.31.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (68.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (1.62.1)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (3.0.5)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 6)) (0.36.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 6)) (0.41.2)\r\n",
      "Requirement already satisfied: rich in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->-r requirements.txt (line 6)) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->-r requirements.txt (line 6)) (0.0.7)\r\n",
      "Requirement already satisfied: dm-tree in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->-r requirements.txt (line 6)) (0.1.8)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 6)) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 6)) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 6)) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 6)) (2024.2.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r requirements.txt (line 6)) (3.5.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r requirements.txt (line 6)) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r requirements.txt (line 6)) (3.0.1)\r\n",
      "Requirement already satisfied: anyascii in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions->-r requirements.txt (line 5)) (0.3.2)\r\n",
      "Requirement already satisfied: pyahocorasick in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions->-r requirements.txt (line 5)) (2.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow->-r requirements.txt (line 6)) (2.1.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow->-r requirements.txt (line 6)) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow->-r requirements.txt (line 6)) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/louislecouturier/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow->-r requirements.txt (line 6)) (0.1.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:52.725890Z",
     "start_time": "2024-03-14T07:56:52.266013Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.361832Z",
     "start_time": "2024-03-14T07:56:52.726620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.375493Z",
     "start_time": "2024-03-14T07:56:53.370431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column :\n",
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values in each column :\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove the rows with missing values and remove the id column as it is not relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.413078Z",
     "start_time": "2024-03-14T07:56:53.381573Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "del data[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now clean and ready for analysis !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.414553Z",
     "start_time": "2024-03-14T07:56:53.390185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        comment_text  toxic  severe_toxic  \\\n0  Explanation\\nWhy the edits made under my usern...      0             0   \n1  D'aww! He matches this background colour I'm s...      0             0   \n2  Hey man, I'm really not trying to edit war. It...      0             0   \n3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n4  You, sir, are my hero. Any chance you remember...      0             0   \n\n   obscene  threat  insult  identity_hate  \n0        0       0       0              0  \n1        0       0       0              0  \n2        0       0       0              0  \n3        0       0       0              0  \n4        0       0       0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.441233Z",
     "start_time": "2024-03-14T07:56:53.392860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neutral comments : 143346\n",
      "\n",
      "Number of toxic comments : 16225\n",
      "| number of severe_toxic : 1595\n",
      "| number of obscene : 8449\n",
      "| number of threat : 478\n",
      "| number of insult : 7877\n",
      "| number of identity_hate : 1405\n"
     ]
    }
   ],
   "source": [
    "from helpers.data.dataset import print_data_composition\n",
    "\n",
    "print_data_composition(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There is clearly imbalanced. The number of neutral comments is way greater than the number of toxic comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Rebalance the dataframe using downsampling\n",
    "\n",
    "We remove neutral comments to balance the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neutral comments : 143346\n",
      "\n",
      "Number of toxic comments : 16225\n",
      "| number of severe_toxic : 1595\n",
      "| number of obscene : 8449\n",
      "| number of threat : 478\n",
      "| number of insult : 7877\n",
      "| number of identity_hate : 1405\n"
     ]
    }
   ],
   "source": [
    "print_data_composition(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.488007Z",
     "start_time": "2024-03-14T07:56:53.406365Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment_text  toxic  \\\n6            COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n12      Hey... what is it..\\n@ | talk .\\nWhat is it......      1   \n16      Bye! \\n\\nDon't look, come or think of comming ...      1   \n42      You are gay or antisemmitian? \\n\\nArchangel WH...      1   \n43               FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1   \n...                                                   ...    ...   \n159494  \"\\n\\n our previous conversation \\n\\nyou fuckin...      1   \n159514                  YOU ARE A MISCHIEVIOUS PUBIC HAIR      1   \n159541  Your absurd edits \\n\\nYour absurd edits on gre...      1   \n159546  \"\\n\\nHey listen don't you ever!!!! Delete my e...      1   \n159554  and i'm going to keep posting the stuff u dele...      1   \n\n        severe_toxic  obscene  threat  insult  identity_hate  \n6                  1        1       0       1              0  \n12                 0        0       0       0              0  \n16                 0        0       0       0              0  \n42                 0        1       0       1              1  \n43                 0        1       0       1              0  \n...              ...      ...     ...     ...            ...  \n159494             0        1       0       1              1  \n159514             0        0       0       1              0  \n159541             0        1       0       1              0  \n159546             0        0       0       1              0  \n159554             0        1       0       1              0  \n\n[16225 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159494</th>\n      <td>\"\\n\\n our previous conversation \\n\\nyou fuckin...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>159514</th>\n      <td>YOU ARE A MISCHIEVIOUS PUBIC HAIR</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159541</th>\n      <td>Your absurd edits \\n\\nYour absurd edits on gre...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159546</th>\n      <td>\"\\n\\nHey listen don't you ever!!!! Delete my e...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159554</th>\n      <td>and i'm going to keep posting the stuff u dele...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>16225 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of comments that have at least one label set to 1\n",
    "toxic_comments = data[(data[\"toxic\"] == 1) |\n",
    "                      (data[\"severe_toxic\"] == 1) |\n",
    "                      (data[\"obscene\"] == 1) |\n",
    "                      (data[\"threat\"] == 1) |\n",
    "                      (data[\"insult\"] == 1) |\n",
    "                      (data[\"identity_hate\"] == 1)]\n",
    "\n",
    "toxic_comments\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.510406Z",
     "start_time": "2024-03-14T07:56:53.418312Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Downsample the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.517479Z",
     "start_time": "2024-03-14T07:56:53.427613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neutral comments : 32450\n",
      "\n",
      "Number of toxic comments : 16225\n",
      "| number of severe_toxic : 1595\n",
      "| number of obscene : 8449\n",
      "| number of threat : 478\n",
      "| number of insult : 7877\n",
      "| number of identity_hate : 1405\n"
     ]
    }
   ],
   "source": [
    "num_toxic_comments = len(toxic_comments)\n",
    "num_neutral_comments = len(data[(data[\"toxic\"] == 0) &\n",
    "                                (data[\"severe_toxic\"] == 0) &\n",
    "                                (data[\"obscene\"] == 0) &\n",
    "                                (data[\"threat\"] == 0) &\n",
    "                                (data[\"insult\"] == 0) &\n",
    "                                (data[\"identity_hate\"] == 0)])\n",
    "\n",
    "num_samples = min(num_toxic_comments, num_neutral_comments)\n",
    "\n",
    "neutral_comments = data[(data[\"toxic\"] == 0) &\n",
    "                        (data[\"severe_toxic\"] == 0) &\n",
    "                        (data[\"obscene\"] == 0) &\n",
    "                        (data[\"threat\"] == 0) &\n",
    "                        (data[\"insult\"] == 0) &\n",
    "                        (data[\"identity_hate\"] == 0)].sample(n=num_samples * 2)\n",
    "\n",
    "data = pd.concat([toxic_comments, neutral_comments])\n",
    "\n",
    "print_data_composition(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:53.518589Z",
     "start_time": "2024-03-14T07:56:53.450973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "6          COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n12    Hey... what is it..\\n@ | talk .\\nWhat is it......\n16    Bye! \\n\\nDon't look, come or think of comming ...\n42    You are gay or antisemmitian? \\n\\nArchangel WH...\n43             FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\nName: comment_text, dtype: object"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"comment_text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:57.852538Z",
     "start_time": "2024-03-14T07:56:53.454719Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers.data.process_comment import process_comment\n",
    "from helpers.data.text_manipulation import TextManipulation\n",
    "\n",
    "text_manipulator = TextManipulation()\n",
    "\n",
    "comments = data[\"comment_text\"].to_numpy()\n",
    "\n",
    "labels_columns = [\n",
    "    \"toxic\",\n",
    "    \"severe_toxic\",\n",
    "    \"obscene\",\n",
    "    \"threat\",\n",
    "    \"insult\",\n",
    "    \"identity_hate\",\n",
    "]\n",
    "labels = data[labels_columns].to_numpy()\n",
    "\n",
    "for i, comment in enumerate(comments):\n",
    "    comments[i] = process_comment(comment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tokenize the comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:56:57.858126Z",
     "start_time": "2024-03-14T07:56:57.852872Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_TOKENS = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:02.520318Z",
     "start_time": "2024-03-14T07:56:57.854988Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_TOKENS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(comments)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:03.506559Z",
     "start_time": "2024-03-14T07:57:02.531987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[595, 152, 3, 1, 285, 17, 24, 155], [244, 36, 8, 12, 53, 36, 8, 12, 31, 1, 468, 9, 63, 641, 1, 14, 100, 41, 1, 1, 1, 56, 1, 69, 62, 54, 56, 1, 90, 300, 40, 92, 1, 7, 1, 1, 41, 641, 227, 1, 4, 1329, 69, 70, 835, 94, 297, 32, 1, 1051], [1, 21, 11, 153, 230, 27, 72, 9, 1, 149, 1], [3, 14, 148, 27, 1, 1, 571, 1, 1, 1, 1, 46, 14, 180, 1346, 75, 3, 21, 1, 24, 213, 40, 1, 10, 1, 26, 1, 1, 9, 436, 7, 11, 1, 324, 25, 3, 14, 1, 94, 1, 20, 631, 1, 7, 83, 4, 2, 1, 1, 280, 25, 3, 878, 424, 9, 2, 1, 10, 1, 8, 6, 1, 1, 97, 6, 1, 1, 17, 20, 1, 83, 4, 2, 1, 1, 23, 20, 148, 1, 383, 120, 7, 254, 418, 3, 106, 148, 5, 33, 11, 658, 25, 62, 65, 801, 1, 45, 342, 13, 24, 34, 5, 21, 11, 510, 4, 53, 4, 3, 986, 1, 9, 2, 1, 654], [47, 20, 1, 540, 13, 2, 122, 1]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(comments)\n",
    "print(sequences[:5])\n",
    "comments = pad_sequences(sequences, padding=\"post\", maxlen=MAX_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:03.515496Z",
     "start_time": "2024-03-14T07:57:03.507251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[595, 152,   3,   1, 285,  17,  24, 155,   0,   0],\n       [244,  36,   8,  12,  53,  36,   8,  12,  31,   1],\n       [  1,  21,  11, 153, 230,  27,  72,   9,   1, 149],\n       [  3,  14, 148,  27,   1,   1, 571,   1,   1,   1],\n       [ 47,  20,   1, 540,  13,   2, 122,   1,   0,   0]], dtype=int32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[:5, :10]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(48675, 1500)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:03.521477Z",
     "start_time": "2024-03-14T07:57:03.510136Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyse the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Split the training and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:03.616663Z",
     "start_time": "2024-03-14T07:57:03.514295Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(comments, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:03.617669Z",
     "start_time": "2024-03-14T07:57:03.594552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data samples : 38940\n",
      "Test data samples : 9735\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data samples : {len(X_train)}\")\n",
    "print(f\"Test data samples : {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:03.618190Z",
     "start_time": "2024-03-14T07:57:03.597010Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models/GRU/model.keras\"\n",
    "VECTORIZER_PATH = \"models/GRU/vectorizer.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "with open(VECTORIZER_PATH, \"wb\") as f:\n",
    "    joblib.dump(tokenizer, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:04.360477Z",
     "start_time": "2024-03-14T07:57:03.599648Z"
    }
   },
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the model\n",
    "### Load GloVe embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "GLOVE_PATH = 'GloVe/glove.6B.100d.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:04.366015Z",
     "start_time": "2024-03-14T07:57:04.361013Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(GLOVE_PATH) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < MAX_TOKENS:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:08.250780Z",
     "start_time": "2024-03-14T07:57:04.363403Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### HYPER-PARAMETERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:08.256830Z",
     "start_time": "2024-03-14T07:57:08.250851Z"
    }
   },
   "outputs": [],
   "source": [
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:08.394156Z",
     "start_time": "2024-03-14T07:57:08.254244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1500\u001B[0m, \u001B[38;5;34m100\u001B[0m)      │    \u001B[38;5;34m10,852,700\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001B[38;5;33mBidirectional\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1500\u001B[0m, \u001B[38;5;34m200\u001B[0m)      │       \u001B[38;5;34m121,200\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1500\u001B[0m, \u001B[38;5;34m200\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n│ (\u001B[38;5;33mGlobalMaxPooling1D\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │        \u001B[38;5;34m20,100\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │           \u001B[38;5;34m400\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │           \u001B[38;5;34m606\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,852,700</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">121,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">606</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m10,995,006\u001B[0m (41.94 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,995,006</span> (41.94 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m10,994,806\u001B[0m (41.94 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,994,806</span> (41.94 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m200\u001B[0m (800.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> (800.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, GlobalMaxPool1D, GRU, Embedding, BatchNormalization, Dropout\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "number_of_classes = len(labels_columns)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(MAX_TOKENS,)))\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM,\n",
    "                    embeddings_initializer=Constant(embedding_matrix), trainable=False))\n",
    "#\n",
    "model.add(Bidirectional(GRU(EMBEDDING_DIM, return_sequences=True)))\n",
    "model.add(Dropout(DROPOUT))\n",
    "#\n",
    "model.add(GlobalMaxPool1D())\n",
    "#\n",
    "model.add(Dense(EMBEDDING_DIM, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(DROPOUT))\n",
    "#\n",
    "model.add(Dense(number_of_classes, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", metrics=[\"accuracy\"], loss=\"binary_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:08.395397Z",
     "start_time": "2024-03-14T07:57:08.393143Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "# loss: 0.8851 - accuracy: 0.1714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:21.398839Z",
     "start_time": "2024-03-14T07:57:08.395846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001B[1m  9/974\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m16:53\u001B[0m 1s/step - accuracy: 0.2170 - loss: 0.7824"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m      2\u001B[0m     X_train,\n\u001B[1;32m      3\u001B[0m     y_train,\n\u001B[1;32m      4\u001B[0m     epochs\u001B[38;5;241m=\u001B[39mNUM_EPOCHS,\n\u001B[1;32m      5\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE,\n\u001B[1;32m      6\u001B[0m     validation_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m\n\u001B[1;32m      7\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:118\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    322\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 323\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[1;32m    324\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(\n\u001B[1;32m    325\u001B[0m         step, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    326\u001B[0m     )\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    879\u001B[0m     args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config\n\u001B[1;32m    880\u001B[0m )\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[1;32m    141\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mcall_preflattened(args)\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall_flat(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mflat_outputs),\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1498\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1500\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[1;32m   1501\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1502\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   1503\u001B[0m       inputs\u001B[38;5;241m=\u001B[39mtensor_inputs,\n\u001B[1;32m   1504\u001B[0m       attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[1;32m   1505\u001B[0m       ctx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1506\u001B[0m   )\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1508\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1509\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1510\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1514\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1515\u001B[0m   )\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:57:21.402066Z",
     "start_time": "2024-03-14T07:57:21.399308Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(X_test, y_test)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T07:57:21.402688Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = [\"I love you so much, you are the best person in the world\"]\n",
    "\n",
    "sentence = process_comment(sentence[0])\n",
    "print(sentence)\n",
    "\n",
    "sentence = tokenizer.texts_to_sequences([sentence])\n",
    "print(sentence)\n",
    "sentence = pad_sequences(sentence, padding=\"post\", maxlen=MAX_TOKENS)\n",
    "\n",
    "print(sentence)\n",
    "\n",
    "prediction = model.predict(sentence)\n",
    "print(labels_columns)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T07:57:21.403658Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinected",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
